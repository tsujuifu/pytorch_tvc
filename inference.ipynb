{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "389670af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '6, 7'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ab7a838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONST: 1024 1025 1026 1027 1028 1029\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import torch as T\n",
    "\n",
    "from omegaconf import OmegaConf\n",
    "from taming.models.vqgan import VQModel\n",
    "\n",
    "from tats.CONST import *\n",
    "from tats import Net2NetTransformer\n",
    "from tats.modules.gpt import sample_with_past\n",
    "print('CONST:', SOS, SPAN, BOS, EOS, PAD, SEP)\n",
    "\n",
    "import clip\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e54d231",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('./_input/data.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55f798b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with z of shape (1, 256, 8, 8) = 16384 dimensions.\n",
      "loaded pretrained LPIPS loss from taming/modules/autoencoder/lpips/vgg.pth\n",
      "VQLPIPSWithDiscriminator running with hinge loss.\n"
     ]
    }
   ],
   "source": [
    "cfg = OmegaConf.load('./_ckpt/yaml_taming_128.yaml')\n",
    "VQ = VQModel(**cfg.model.params).eval().cuda()\n",
    "_ = VQ.load_state_dict(T.load('./_ckpt/ckpt_taming_mugen_128.pt', map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "679fd7bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- (FIRST, COND, GPT): 16384 49408 65792 -----\n",
      "----- (LEN_VIDEO, VOC_COND): 16 49408 -----\n"
     ]
    }
   ],
   "source": [
    "gpt = Net2NetTransformer._load_model_state(T.load('./_ckpt/ckpt_mmvg_mugen.pt', map_location='cpu')).eval().cuda()\n",
    "\n",
    "LEN_VIDEO, VOC_COND = gpt.args.sequence_length, gpt.cond_stage_vocab_size\n",
    "print('----- (LEN_VIDEO, VOC_COND):', LEN_VIDEO, VOC_COND, '-----')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82b2ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_post(dat):\n",
    "    pix = (((dat.permute(0, 2, 3, 1)+1.0)/2.0).clamp(0, 1).cpu().numpy()*255.0).astype(np.uint8)\n",
    "    return pix\n",
    "\n",
    "def prepare(typ, item):\n",
    "    if typ=='prediction' or typ=='rewind': z = item['img']\n",
    "    elif typ=='infilling': z0, z1 = item['img0'], item['img1']\n",
    "    \n",
    "    if typ=='prediction': cz = [PAD]+z.flatten().tolist()+[SPAN]\n",
    "    elif typ=='rewind': cz = [SPAN]+z.flatten().tolist()+[PAD]\n",
    "    elif typ=='infilling': cz = [PAD]+z0.flatten().tolist()+[SPAN]+z1.flatten().tolist()+[PAD]\n",
    "    cz += [PAD for _ in range(262-len(cz))]\n",
    "    cz += [BOS]\n",
    "    cz = [c+VOC_COND for c in cz]\n",
    "    cx = clip.tokenize(item['ins'], context_length=100, truncate=True)[0].numpy().tolist()\n",
    "    c = T.from_numpy(np.array(cx+cz, np.int64))\n",
    "    \n",
    "    return c\n",
    "\n",
    "def post(d):\n",
    "    try: p = T.where(d==EOS)[0][0].item()\n",
    "    except: p = 64*LEN_VIDEO\n",
    "    l = p//64\n",
    "    d = d[:l*64].clip(0, 1023).view([l, 8, 8])\n",
    "    return d\n",
    "\n",
    "def run(c, step):\n",
    "    with T.no_grad(): outs = sample_with_past(c.cuda(), gpt.transformer, steps=step, sample_logits=False, \n",
    "                                              temperature=1.0, top_k=10, top_p=0.98)\n",
    "    frames = []\n",
    "    for out in outs:\n",
    "        z = post(out-VOC_COND)\n",
    "        with T.no_grad(): out = VQ.decode(VQ.quantize.embedding(z.cuda()).permute(0, 3, 1, 2))\n",
    "        pix = img_post(out)\n",
    "        frames.append([Image.fromarray(f).convert('RGB') for f in pix])\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2211b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0 Mugen jumps up to the platform on the right and collects two coins. -----\n",
      "----- 1 Mugen jumps onto the ladder and then down onto the level to collect a coin. -----\n",
      "----- 2 Mugen heads left and jumps onto a face, crushing it, while collecting a coin. It then heads back right and jumps down to the ground-level. -----\n",
      "----- 3 Mugen collects a coin, and then a mouse runs into it from behind. -----\n"
     ]
    }
   ],
   "source": [
    "cs = []\n",
    "for idx, item in enumerate(data['prediction']):\n",
    "    img, ins = item['img'], item['ins']\n",
    "    print('-----', idx, ins, '-----')\n",
    "    c = prepare('prediction', {'img': img, 'ins': ins})\n",
    "    cs.append(c.unsqueeze(0))\n",
    "cs = T.cat(cs, dim=0)\n",
    "\n",
    "frames = run(cs, (64*16+3)-1)\n",
    "for idx, frame in enumerate(frames):\n",
    "    frame[0].save('./_output/vp_%d.gif'%(idx), format='GIF', append_images=frame, \n",
    "                  duration=int(1000.0/5.0), save_all=True, loop=0, \n",
    "                  quality=100, sub_sampling=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91fa3427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0 Mugen jumps up and down a few times. -----\n",
      "----- 1 Mugen runs right to left and it jump runs left to right and it collect coin and gem. -----\n",
      "----- 2 Mugen walks to the right while on the ground level at a steady pace before jumping up to the platform. It collects a gem on this small platform and drops back down to the ground level. -----\n",
      "----- 3 Mugen jumps onto a platform and moves from left to right, collects a coin, then jumps onto snail, squishing it. Mugen then passes under a bee and moves off the right edge of the platform, landing on the ground. -----\n"
     ]
    }
   ],
   "source": [
    "cs = []\n",
    "for idx, item in enumerate(data['rewind']):\n",
    "    img, ins = item['img'], item['ins']\n",
    "    print('-----', idx, ins, '-----')\n",
    "    c = prepare('rewind', {'img': img, 'ins': ins})\n",
    "    cs.append(c.unsqueeze(0))\n",
    "cs = T.cat(cs, dim=0)\n",
    "\n",
    "frames = run(cs, (64*16+3)-1)\n",
    "for idx, frame in enumerate(frames):\n",
    "    frame[0].save('./_output/vr_%d.gif'%(idx), format='GIF', append_images=frame, \n",
    "                  duration=int(1000.0/5.0), save_all=True, loop=0, \n",
    "                  quality=100, sub_sampling=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9f55026",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- 0 Mugen moves left. It jumps through a narrow gap up to a platform and moves right to collect coins. -----\n",
      "----- 1 Mugen runs from left to right. it jumps over a gear, then make a run to collect a coin. -----\n",
      "----- 2 Mugen bounced to the left two times, then bounced one time back to the right once it saw the wall. -----\n",
      "----- 3 Mugen hops up and hits it head. It then leaps up on the platform and jumps to smash the worm after collecting a coin and then turns back left. -----\n"
     ]
    }
   ],
   "source": [
    "cs = []\n",
    "for idx, item in enumerate(data['infilling']):\n",
    "    img0, img1, ins = item['img0'], item['img1'], item['ins']\n",
    "    print('-----', idx, ins, '-----')\n",
    "    c = prepare('infilling', {'img0': img0, 'img1': img1, 'ins': ins})\n",
    "    cs.append(c.unsqueeze(0))\n",
    "cs = T.cat(cs, dim=0)\n",
    "\n",
    "frames = run(cs, (64*16+3)-1)\n",
    "for idx, frame in enumerate(frames):\n",
    "    frame[0].save('./_output/vi_%d.gif'%(idx), format='GIF', append_images=frame, \n",
    "                  duration=int(1000.0/5.0), save_all=True, loop=0, \n",
    "                  quality=100, sub_sampling=0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
